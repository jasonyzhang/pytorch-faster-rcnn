{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import _init_paths\n",
    "from model.config import cfg\n",
    "from model.test import im_detect\n",
    "from model.nms_wrapper import nms\n",
    "from nets.vgg16 import vgg16\n",
    "from nets.resnet_v1 import resnetv1\n",
    "from utils.timer import Timer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETS = {\n",
    "    'vgg16': ('vgg16_faster_rcnn_iter_%d.pth',),\n",
    "    'res101': ('res101_faster_rcnn_iter_%d.pth',),\n",
    "}\n",
    "\n",
    "DATASETS= {\n",
    "    'pascal_voc': ('voc_2007_trainval',),\n",
    "    'pascal_voc_0712': ('voc_2007_trainval+voc_2012_trainval',),\n",
    "}\n",
    "\n",
    "IMAGE_DIRECTORY = 'frames/gangnam'\n",
    "SAVE_DIRECTORY = 'output/gangnam'\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "#IMAGE_DIRECTORY = 'demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_detections(im, class_name, dets, thresh=0.5, save_fig=False, fname=None):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "        \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save_fig:\n",
    "        save_file = os.path.join(cfg.DATA_DIR, SAVE_DIRECTORY, fname)\n",
    "        plt.savefig(save_file)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_person(net, image_name, save_fig=False):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "    im_file = os.path.join(cfg.DATA_DIR, IMAGE_DIRECTORY, image_name)\n",
    "    im = cv2.imread(im_file)\n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    scores, boxes = im_detect(net, im)\n",
    "    timer.toc()\n",
    "    print('Detection took {:.3f}s for {:d} object proposals'.format(timer.total_time(), boxes.shape[0]))\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    conf_thresh = 0.8\n",
    "    nms_thresh = 0.3\n",
    "    \n",
    "    cls_ind = 15\n",
    "    cls = 'Person'\n",
    "    cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "    cls_scores = scores[:, cls_ind]\n",
    "    dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "    keep = nms(torch.from_numpy(dets), nms_thresh)\n",
    "    dets = dets[keep.numpy(), :]\n",
    "    vis_detections(im, cls, dets, thresh=conf_thresh, save_fig=save_fig, fname=image_name)\n",
    "    return scores, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded network ../output/res101/voc_2007_trainval+voc_2012_trainval/default/res101_faster_rcnn_iter_110000.pth\n"
     ]
    }
   ],
   "source": [
    "demonet = 'res101' # Network to use [vgg16 res101]\n",
    "dataset = 'pascal_voc_0712' # Trained dataset [pascal_voc pascal_voc_0712]\n",
    "\n",
    "cfg.TEST.HAS_RPN = True  # Use RPN for proposals\n",
    "cfg.TEST.RPN_POST_NMS_TOP_N = 300 # Paper uses 2000 region proposals\n",
    "\n",
    "# model path\n",
    "saved_model = os.path.join('../output', demonet, DATASETS[dataset][0], 'default',\n",
    "                          NETS[demonet][0] %(70000 if dataset == 'pascal_voc' else 110000))\n",
    "\n",
    "\n",
    "# load network\n",
    "net = resnetv1(num_layers=101)\n",
    "net.create_architecture(21, tag='default', anchor_scales=[8, 16, 32])\n",
    "\n",
    "net.load_state_dict(torch.load(saved_model, map_location=lambda storage, loc: storage))\n",
    "\n",
    "net.eval()\n",
    "net._device = 'cpu'\n",
    "net.to(net._device)\n",
    "\n",
    "print('Loaded network {:s}'.format(saved_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_000009.jpg\n",
      "Detection took 25.459s for 300 object proposals\n",
      "frame_000021.jpg\n",
      "Detection took 31.218s for 300 object proposals\n",
      "frame_000033.jpg\n",
      "Detection took 30.742s for 300 object proposals\n",
      "frame_000045.jpg\n",
      "Detection took 31.278s for 300 object proposals\n",
      "frame_000057.jpg\n",
      "Detection took 28.747s for 265 object proposals\n",
      "frame_000069.jpg\n",
      "Detection took 25.946s for 229 object proposals\n",
      "frame_000081.jpg\n",
      "Detection took 24.823s for 213 object proposals\n",
      "frame_000093.jpg\n",
      "Detection took 24.263s for 195 object proposals\n",
      "frame_000105.jpg\n",
      "Detection took 25.569s for 225 object proposals\n",
      "frame_000117.jpg\n",
      "Detection took 29.420s for 275 object proposals\n",
      "frame_000129.jpg\n",
      "Detection took 30.478s for 291 object proposals\n",
      "frame_000141.jpg\n",
      "Detection took 19.718s for 141 object proposals\n",
      "frame_000153.jpg\n",
      "Detection took 17.986s for 130 object proposals\n",
      "frame_000165.jpg\n",
      "Detection took 16.183s for 109 object proposals\n",
      "frame_000177.jpg\n",
      "Detection took 16.844s for 109 object proposals\n",
      "frame_000189.jpg\n",
      "Detection took 16.725s for 115 object proposals\n",
      "frame_000201.jpg\n",
      "Detection took 17.227s for 120 object proposals\n",
      "frame_000213.jpg\n",
      "Detection took 17.595s for 123 object proposals\n",
      "frame_000225.jpg\n",
      "Detection took 17.699s for 117 object proposals\n",
      "frame_000237.jpg\n",
      "Detection took 18.557s for 125 object proposals\n",
      "frame_000249.jpg\n",
      "Detection took 17.630s for 118 object proposals\n",
      "frame_000261.jpg\n",
      "Detection took 18.353s for 126 object proposals\n",
      "frame_000273.jpg\n",
      "Detection took 27.572s for 247 object proposals\n",
      "frame_000285.jpg\n",
      "Detection took 28.283s for 243 object proposals\n",
      "frame_000297.jpg\n",
      "Detection took 31.543s for 300 object proposals\n",
      "frame_000309.jpg\n",
      "Detection took 31.766s for 300 object proposals\n",
      "frame_000321.jpg\n",
      "Detection took 32.398s for 300 object proposals\n",
      "frame_000333.jpg\n",
      "Detection took 32.570s for 300 object proposals\n",
      "frame_000345.jpg\n",
      "Detection took 32.882s for 300 object proposals\n",
      "frame_000357.jpg\n",
      "Detection took 31.890s for 300 object proposals\n",
      "frame_000369.jpg\n",
      "Detection took 31.182s for 300 object proposals\n",
      "frame_000381.jpg\n",
      "Detection took 31.606s for 300 object proposals\n",
      "frame_000393.jpg\n",
      "Detection took 31.308s for 300 object proposals\n",
      "frame_000405.jpg\n",
      "Detection took 31.820s for 300 object proposals\n",
      "frame_000417.jpg\n",
      "Detection took 34.227s for 300 object proposals\n",
      "frame_000429.jpg\n",
      "Detection took 34.098s for 300 object proposals\n",
      "frame_000441.jpg\n",
      "Detection took 32.820s for 300 object proposals\n",
      "frame_000453.jpg\n",
      "Detection took 33.810s for 300 object proposals\n",
      "frame_000465.jpg\n",
      "Detection took 32.381s for 300 object proposals\n",
      "frame_000477.jpg\n",
      "Detection took 31.958s for 300 object proposals\n",
      "frame_000489.jpg\n",
      "Detection took 33.254s for 300 object proposals\n",
      "frame_000501.jpg\n",
      "Detection took 33.341s for 300 object proposals\n",
      "frame_000513.jpg\n",
      "Detection took 31.910s for 300 object proposals\n",
      "frame_000525.jpg\n",
      "Detection took 32.190s for 300 object proposals\n",
      "frame_000537.jpg\n",
      "Detection took 32.093s for 300 object proposals\n",
      "frame_000549.jpg\n",
      "Detection took 32.713s for 300 object proposals\n",
      "frame_000561.jpg\n",
      "Detection took 33.032s for 300 object proposals\n",
      "frame_000573.jpg\n",
      "Detection took 32.112s for 300 object proposals\n",
      "frame_000585.jpg\n",
      "Detection took 31.625s for 300 object proposals\n",
      "frame_000597.jpg\n",
      "Detection took 31.815s for 300 object proposals\n",
      "frame_000609.jpg\n",
      "Detection took 32.128s for 300 object proposals\n",
      "frame_000621.jpg\n",
      "Detection took 31.350s for 300 object proposals\n",
      "frame_000633.jpg\n",
      "Detection took 32.269s for 300 object proposals\n",
      "frame_000645.jpg\n",
      "Detection took 31.874s for 300 object proposals\n",
      "frame_000657.jpg\n",
      "Detection took 31.448s for 264 object proposals\n",
      "frame_000669.jpg\n",
      "Detection took 31.663s for 300 object proposals\n",
      "frame_000681.jpg\n",
      "Detection took 30.653s for 300 object proposals\n",
      "frame_000693.jpg\n",
      "Detection took 30.441s for 300 object proposals\n",
      "frame_000705.jpg\n",
      "Detection took 30.692s for 300 object proposals\n",
      "frame_000717.jpg\n",
      "Detection took 31.173s for 300 object proposals\n",
      "frame_000729.jpg\n",
      "Detection took 31.276s for 300 object proposals\n",
      "frame_000741.jpg\n",
      "Detection took 30.825s for 300 object proposals\n",
      "frame_000753.jpg\n",
      "Detection took 30.814s for 300 object proposals\n",
      "frame_000765.jpg\n",
      "Detection took 30.190s for 300 object proposals\n",
      "frame_000777.jpg\n",
      "Detection took 30.452s for 300 object proposals\n",
      "frame_000789.jpg\n",
      "Detection took 31.612s for 300 object proposals\n",
      "frame_000801.jpg\n",
      "Detection took 30.290s for 300 object proposals\n",
      "frame_000813.jpg\n",
      "Detection took 30.494s for 300 object proposals\n",
      "frame_000825.jpg\n",
      "Detection took 30.992s for 300 object proposals\n",
      "frame_000837.jpg\n",
      "Detection took 30.185s for 300 object proposals\n",
      "frame_000849.jpg\n",
      "Detection took 30.754s for 300 object proposals\n",
      "frame_000861.jpg\n",
      "Detection took 30.455s for 300 object proposals\n",
      "frame_000873.jpg\n",
      "Detection took 30.318s for 300 object proposals\n",
      "frame_000885.jpg\n",
      "Detection took 29.953s for 300 object proposals\n",
      "frame_000897.jpg\n",
      "Detection took 30.287s for 300 object proposals\n",
      "frame_000909.jpg\n",
      "Detection took 30.110s for 300 object proposals\n",
      "frame_000921.jpg\n",
      "Detection took 30.166s for 300 object proposals\n",
      "frame_000933.jpg\n",
      "Detection took 30.458s for 300 object proposals\n",
      "frame_000945.jpg\n",
      "Detection took 30.952s for 300 object proposals\n",
      "frame_000957.jpg\n",
      "Detection took 30.669s for 300 object proposals\n",
      "frame_000969.jpg\n",
      "Detection took 30.700s for 300 object proposals\n",
      "frame_000981.jpg\n",
      "Detection took 30.344s for 300 object proposals\n",
      "frame_000993.jpg\n",
      "Detection took 30.069s for 300 object proposals\n",
      "frame_001005.jpg\n",
      "Detection took 29.563s for 300 object proposals\n",
      "frame_001017.jpg\n",
      "Detection took 29.730s for 300 object proposals\n",
      "frame_001029.jpg\n",
      "Detection took 29.789s for 300 object proposals\n",
      "frame_001041.jpg\n",
      "Detection took 29.839s for 300 object proposals\n",
      "frame_001053.jpg\n",
      "Detection took 29.499s for 300 object proposals\n",
      "frame_001065.jpg\n",
      "Detection took 29.618s for 300 object proposals\n",
      "frame_001077.jpg\n",
      "Detection took 30.125s for 300 object proposals\n",
      "frame_001089.jpg\n",
      "Detection took 30.237s for 300 object proposals\n",
      "frame_001101.jpg\n",
      "Detection took 30.711s for 300 object proposals\n",
      "frame_001113.jpg\n",
      "Detection took 30.079s for 299 object proposals\n",
      "frame_001125.jpg\n",
      "Detection took 30.563s for 300 object proposals\n",
      "frame_001137.jpg\n",
      "Detection took 30.884s for 300 object proposals\n",
      "frame_001149.jpg\n",
      "Detection took 29.853s for 300 object proposals\n",
      "frame_001161.jpg\n",
      "Detection took 30.249s for 300 object proposals\n",
      "frame_001173.jpg\n",
      "Detection took 29.577s for 300 object proposals\n",
      "frame_001185.jpg\n",
      "Detection took 30.312s for 300 object proposals\n",
      "frame_001197.jpg\n",
      "Detection took 29.535s for 300 object proposals\n",
      "frame_001209.jpg\n",
      "Detection took 30.017s for 300 object proposals\n",
      "frame_001221.jpg\n",
      "Detection took 30.151s for 300 object proposals\n",
      "frame_001233.jpg\n",
      "Detection took 30.552s for 300 object proposals\n",
      "frame_001245.jpg\n",
      "Detection took 30.423s for 300 object proposals\n",
      "frame_001257.jpg\n",
      "Detection took 30.753s for 300 object proposals\n",
      "frame_001269.jpg\n",
      "Detection took 29.950s for 300 object proposals\n",
      "frame_001281.jpg\n",
      "Detection took 29.989s for 300 object proposals\n",
      "frame_001293.jpg\n",
      "Detection took 30.510s for 300 object proposals\n",
      "frame_001305.jpg\n",
      "Detection took 30.335s for 300 object proposals\n",
      "frame_001317.jpg\n",
      "Detection took 30.002s for 300 object proposals\n",
      "frame_001329.jpg\n",
      "Detection took 30.224s for 300 object proposals\n",
      "frame_001341.jpg\n",
      "Detection took 29.889s for 300 object proposals\n",
      "frame_001353.jpg\n",
      "Detection took 29.579s for 300 object proposals\n",
      "frame_001365.jpg\n",
      "Detection took 30.345s for 300 object proposals\n",
      "frame_001377.jpg\n",
      "Detection took 30.129s for 300 object proposals\n",
      "frame_001389.jpg\n",
      "Detection took 30.281s for 300 object proposals\n",
      "frame_001401.jpg\n",
      "Detection took 29.988s for 300 object proposals\n",
      "frame_001413.jpg\n",
      "Detection took 29.857s for 300 object proposals\n",
      "frame_001425.jpg\n",
      "Detection took 28.035s for 278 object proposals\n",
      "frame_001437.jpg\n",
      "Detection took 30.680s for 300 object proposals\n",
      "frame_001449.jpg\n",
      "Detection took 29.921s for 300 object proposals\n",
      "frame_001461.jpg\n",
      "Detection took 29.700s for 300 object proposals\n",
      "frame_001473.jpg\n",
      "Detection took 30.345s for 300 object proposals\n",
      "frame_001485.jpg\n",
      "Detection took 31.102s for 300 object proposals\n",
      "frame_001497.jpg\n",
      "Detection took 30.673s for 300 object proposals\n",
      "frame_001509.jpg\n",
      "Detection took 29.855s for 300 object proposals\n",
      "frame_001521.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection took 29.995s for 300 object proposals\n",
      "frame_001533.jpg\n",
      "Detection took 30.472s for 300 object proposals\n",
      "frame_001545.jpg\n",
      "Detection took 30.454s for 300 object proposals\n",
      "frame_001557.jpg\n",
      "Detection took 29.544s for 300 object proposals\n",
      "frame_001569.jpg\n",
      "Detection took 29.880s for 300 object proposals\n",
      "frame_001581.jpg\n",
      "Detection took 30.310s for 300 object proposals\n",
      "frame_001593.jpg\n",
      "Detection took 30.912s for 300 object proposals\n",
      "frame_001605.jpg\n",
      "Detection took 30.539s for 300 object proposals\n",
      "frame_001617.jpg\n",
      "Detection took 29.973s for 300 object proposals\n",
      "frame_001629.jpg\n",
      "Detection took 29.853s for 300 object proposals\n",
      "frame_001641.jpg\n",
      "Detection took 31.814s for 300 object proposals\n",
      "frame_001653.jpg\n",
      "Detection took 36.447s for 300 object proposals\n",
      "frame_001665.jpg\n",
      "Detection took 37.786s for 297 object proposals\n",
      "frame_001677.jpg\n",
      "Detection took 35.355s for 267 object proposals\n",
      "frame_001689.jpg\n",
      "Detection took 26.100s for 223 object proposals\n",
      "frame_001701.jpg\n",
      "Detection took 16.995s for 121 object proposals\n",
      "frame_001713.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8e8b15a1d5f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mim_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_person\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_fig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4590ecaf4a63>\u001b[0m in \u001b[0;36mdetect_person\u001b[0;34m(net, image_name, save_fig)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Detection took {:.3f}s for {:d} object proposals'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/rcnn/pytorch-faster-rcnn/tools/../lib/model/test.py\u001b[0m in \u001b[0;36mim_detect\u001b[0;34m(net, im)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'im_info'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'im_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mim_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/rcnn/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36mtest_image\u001b[0;34m(self, image, im_info)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TEST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0mcls_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cls_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/rcnn/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, im_info, gt_boxes, mode)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TEST'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/rcnn/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TRAIN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# benchmark because now the input size are fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mfc7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head_to_tail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mcls_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_region_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/rcnn/pytorch-faster-rcnn/tools/../lib/nets/resnet_v1.py\u001b[0m in \u001b[0;36m_head_to_tail\u001b[0;34m(self, pool5)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_head_to_tail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mfc7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# average pooling after layer4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfc7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     47\u001b[0m         return F.batch_norm(\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1193\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frame_skip = 12\n",
    "\n",
    "im_names = sorted(os.listdir(os.path.join(cfg.DATA_DIR, IMAGE_DIRECTORY)))[8::frame_skip]\n",
    "#im_names = ['004545.jpg']\n",
    "\n",
    "for im_name in im_names:\n",
    "    print(im_name)\n",
    "    scores, boxes = detect_person(net, im_name, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
